{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53bcb3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c676bb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/x2tsq5qj4v512jqb_k8l1jgw0000gp/T/ipykernel_8364/1157634455.py:1: DtypeWarning: Columns (9,10,11,12,13,30,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lith_data = pd.read_csv('../data/full_grouped_lithology_training_data.csv')\n"
     ]
    }
   ],
   "source": [
    "lith_data = pd.read_csv('../data/full_grouped_lithology_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5960500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_col = 'LATITUDE'\n",
    "lon_col = 'LONGITUDE'\n",
    "collar_elev_col = 'ELEVATION_FT'\n",
    "top_depth_col = 'TOP_DEPTH_FT'\n",
    "bottom_depth_col = 'BOTTOM_DEPTH_FT'\n",
    "lithology_col = 'SYMBOL_LITHOLOGY'\n",
    "grouped_lithology_col = 'Grouped_Lithology'\n",
    "\n",
    "midpoint_depth_col = 'Midpoint_Depth_ft'\n",
    "midpoint_elev_col = 'Midpoint_Elevation_ft'\n",
    "\n",
    "feature_cols = [lat_col, lon_col, midpoint_depth_col, midpoint_elev_col]\n",
    "\n",
    "target_col = grouped_lithology_col\n",
    "test_size_proportion = 0.25\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc5aa8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features shape (X): (319114, 4)\n",
      "Target shape (y): (319114,)\n",
      "Target variable unique values after cleaning: 9 unique lithology types.\n",
      "\n",
      "Splitting data into training (75%) and testing (25%)...\n",
      "Data split complete.\n",
      "Training features shape (X_train): (239335, 4)\n",
      "Testing features shape (X_test): (79779, 4)\n",
      "Training target shape (y_train): (239335,)\n",
      "Testing target shape (y_test): (79779,)\n",
      "\n",
      "Class distribution comparison (Training vs. Testing):\n",
      "                         Train      Test\n",
      "Grouped_Lithology                       \n",
      "Sand (with Fines)     0.535024  0.535028\n",
      "Silty Soils           0.204855  0.204853\n",
      "Topsoil / vegetation  0.069033  0.069028\n",
      "Clayey Soils          0.058241  0.058236\n",
      "Gravel (with Fines)   0.057522  0.057521\n"
     ]
    }
   ],
   "source": [
    "if lith_data.shape[0] == 0:\n",
    "        raise ValueError(\"No data remaining after cleaning and removing rare classes. Cannot perform split.\")\n",
    "\n",
    "# --- Separate features (X) and target (y) on the filtered data ---\n",
    "X = lith_data[feature_cols]\n",
    "y = lith_data[grouped_lithology_col]\n",
    "\n",
    "print(f\"\\nFeatures shape (X): {X.shape}\")\n",
    "print(f\"Target shape (y): {y.shape}\")\n",
    "print(f\"Target variable unique values after cleaning: {y.unique().shape[0]} unique lithology types.\")\n",
    "\n",
    "\n",
    "# --- Perform the train-test split ---\n",
    "print(f\"\\nSplitting data into training ({1 - test_size_proportion:.0%}) and testing ({test_size_proportion:.0%})...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=test_size_proportion,\n",
    "    random_state=random_seed,\n",
    "    stratify=y # Stratify should now work\n",
    ")\n",
    "\n",
    "print(\"Data split complete.\")\n",
    "print(f\"Training features shape (X_train): {X_train.shape}\")\n",
    "print(f\"Testing features shape (X_test): {X_test.shape}\")\n",
    "print(f\"Training target shape (y_train): {y_train.shape}\")\n",
    "print(f\"Testing target shape (y_test): {y_test.shape}\")\n",
    "\n",
    "# Check class distribution in train/test sets\n",
    "print(\"\\nClass distribution comparison (Training vs. Testing):\")\n",
    "train_dist = y_train.value_counts(normalize=True)\n",
    "test_dist = y_test.value_counts(normalize=True)\n",
    "dist_comparison = pd.DataFrame({'Train': train_dist, 'Test': test_dist})\n",
    "print(dist_comparison.head()) # Print comparison for top classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ddbc8b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lith_data[feature_cols]\n",
    "y = lith_data[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ee92a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features shape (X): (319114, 4)\n",
      "Target shape (y): (319114,)\n",
      "Target variable unique values: ['Anthropogenic Fill/Debris' 'Silty Soils' 'Topsoil / vegetation'\n",
      " 'Sand (with Fines)' 'Clayey Soils' 'Gravel (with Fines)'\n",
      " 'Asphalt / concrete' 'Peat' 'Bedrock']\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFeatures shape (X): {X.shape}\")\n",
    "print(f\"Target shape (y): {y.shape}\")\n",
    "print(f\"Target variable unique values: {y.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "429dc5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c1c189a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=150, random_state=random_seed, class_weight='balanced', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "92fb121a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Lithology Classification Model Training (Random Forest)...\n",
      "Training complete in 24.50 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting Lithology Classification Model Training (Random Forest)...\")\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "print(f\"Training complete in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f31c583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making predictions on the testing data...\n",
      "Predictions complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMaking predictions on the testing data...\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Predictions complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88c1d34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.6682\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on the test set: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "649e1d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "Anthropogenic Fill/Debris       0.58      0.27      0.37      1559\n",
      "       Asphalt / concrete       0.76      0.76      0.76      2325\n",
      "                  Bedrock       0.70      0.59      0.64       806\n",
      "             Clayey Soils       0.52      0.34      0.41      4646\n",
      "      Gravel (with Fines)       0.54      0.31      0.40      4589\n",
      "                     Peat       0.49      0.27      0.35      1320\n",
      "        Sand (with Fines)       0.71      0.85      0.77     42684\n",
      "              Silty Soils       0.54      0.42      0.47     16343\n",
      "     Topsoil / vegetation       0.75      0.76      0.76      5507\n",
      "\n",
      "                 accuracy                           0.67     79779\n",
      "                macro avg       0.62      0.51      0.55     79779\n",
      "             weighted avg       0.65      0.67      0.65     79779\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6d090dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[  421    38     9    20    36     3   840   129    63]\n",
      " [   11  1766     0     0    86     0   168    29   265]\n",
      " [    3     0   476    19    12     1   209    83     3]\n",
      " [   17     2    15  1589    43    25  1860  1073    22]\n",
      " [   25   152    24    52  1444    11  2362   371   148]\n",
      " [    7     1     0    31    27   352   690   181    31]\n",
      " [  148   120   108   724   727   173 36219  3876   589]\n",
      " [   67    31    51   640   205   136  8125  6831   257]\n",
      " [   24   226     0    10    75    12   800   153  4207]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "56c5534d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importances:\n",
      "LONGITUDE                0.264755\n",
      "LATITUDE                 0.261316\n",
      "Midpoint_Depth_ft        0.243953\n",
      "Midpoint_Elevation_ft    0.229976\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFeature Importances:\")\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116aa90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
